# CS224n 발표 자료 아카이브 입니다.
---

- cs224n syllabus: https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/index.html#schedule
- cs224n youtube: https://www.youtube.com/playlist?list=PLQdCGOoR3Oqb9RWevPjMUMwM6nvc0U98F

---

# 발표 현황

| **주차** | **학습 내용** | **과제** | **발표자** | **발표 날짜** |
|----------|---------------|----------|----------|----------|
| **1주차** | 1. Word Vectors, Word Window Classification, Language Models (1, 2강) <br> 2. Backprop and Neural Networks & Dependency Parsing (3, 4강) | - | - | - |
| **2주차** | 1. Recurrent Neural Networks and Language Models & LSTM RNNs (5강, 6강 일부) <br> 2. Neural Machine Translation (6강) & Self-Attention and Transformers (6강 일부, 7강) | - | - | - |
| **3주차** | 1. Pretraining (8강) <br> 2. Natural Language Generation (9강) | - | - | - |
| **4주차** | 1. Prompting, Reinforcement Learning from Human Feedback (10강) <br> 2. Question Answering (11강) <br> 3. Assignment 4: Neural Machine Translation with sequence-to-sequence, attention, and subwords (12%) | Assignment 4 발표 | - | - |
| **5주차** | 1. ConvNets, Tree Recursive Neural Networks and Constituency Parsing (12강) <br> 2. Insights between NLP and Linguistics & Code Generation (13강, 14강) | - | - | - |
| **6주차** | 1. Multimodal Deep Learning & Coreference Resolution (15강, 16강) <br> 2. Analysis and Interpretability Basics, Model Interpretability and Editing (17강, 18강) | - | - | - |
| **7주차** | 1. 4주차에 Assignment 4 발표 못했을 경우, 이때 발표 <br> 2. Assignment 5: Self-supervised learning and fine-tuning with Transformers (12%) | Assignment 5 발표 | - | - |
